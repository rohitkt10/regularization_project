{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trial_03'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = 3\n",
    "f\"trial_{trial:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-5-daa53bcb9e2a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-daa53bcb9e2a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    int(\"000\") + int(001)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "int(\"000\") + int(001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39355985 -0.11586729  0.19599572]\n",
      "[-1.69105083  1.95044657  0.91279094 -0.70167148]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3)\n",
    "y = np.random.randn(4)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"data.h5\", \"w\",)\n",
    "file.create_dataset(name='x', data=x, compression='gzip')\n",
    "file.create_dataset(name='y', data=y, compression='gzip')\n",
    "file.close()\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['x', 'y']>\n",
      "(3,)\n",
      "(4,)\n",
      "[ 0.39355985 -0.11586729  0.19599572]\n",
      "[-1.69105083  1.95044657  0.91279094 -0.70167148]\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File(\"data.h5\", \"r\")\n",
    "print(file.keys())\n",
    "print(file['x'].shape)\n",
    "print(file['y'].shape)\n",
    "print(file['x'][:])\n",
    "print(file['y'][:])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_dataset in module h5py._hl.group:\n",
      "\n",
      "create_dataset(name, shape=None, dtype=None, data=None, **kwds) method of h5py._hl.files.File instance\n",
      "    Create a new HDF5 dataset\n",
      "    \n",
      "    name\n",
      "        Name of the dataset (absolute or relative).  Provide None to make\n",
      "        an anonymous dataset.\n",
      "    shape\n",
      "        Dataset shape.  Use \"()\" for scalar datasets.  Required if \"data\"\n",
      "        isn't provided.\n",
      "    dtype\n",
      "        Numpy dtype or string.  If omitted, dtype('f') will be used.\n",
      "        Required if \"data\" isn't provided; otherwise, overrides data\n",
      "        array's dtype.\n",
      "    data\n",
      "        Provide data to initialize the dataset.  If used, you can omit\n",
      "        shape and dtype arguments.\n",
      "    \n",
      "    Keyword-only arguments:\n",
      "    \n",
      "    chunks\n",
      "        (Tuple or int) Chunk shape, or True to enable auto-chunking. Integers can\n",
      "        be used for 1D shape.\n",
      "    \n",
      "    maxshape\n",
      "        (Tuple or int) Make the dataset resizable up to this shape. Use None for\n",
      "        axes you want to be unlimited. Integers can be used for 1D shape.\n",
      "    compression\n",
      "        (String or int) Compression strategy.  Legal values are 'gzip',\n",
      "        'szip', 'lzf'.  If an integer in range(10), this indicates gzip\n",
      "        compression level. Otherwise, an integer indicates the number of a\n",
      "        dynamically loaded compression filter.\n",
      "    compression_opts\n",
      "        Compression settings.  This is an integer for gzip, 2-tuple for\n",
      "        szip, etc. If specifying a dynamically loaded compression filter\n",
      "        number, this must be a tuple of values.\n",
      "    scaleoffset\n",
      "        (Integer) Enable scale/offset filter for (usually) lossy\n",
      "        compression of integer or floating-point data. For integer\n",
      "        data, the value of scaleoffset is the number of bits to\n",
      "        retain (pass 0 to let HDF5 determine the minimum number of\n",
      "        bits necessary for lossless compression). For floating point\n",
      "        data, scaleoffset is the number of digits after the decimal\n",
      "        place to retain; stored values thus have absolute error\n",
      "        less than 0.5*10**(-scaleoffset).\n",
      "    shuffle\n",
      "        (T/F) Enable shuffle filter.\n",
      "    fletcher32\n",
      "        (T/F) Enable fletcher32 error detection. Not permitted in\n",
      "        conjunction with the scale/offset filter.\n",
      "    fillvalue\n",
      "        (Scalar) Use this value for uninitialized parts of the dataset.\n",
      "    track_times\n",
      "        (T/F) Enable dataset creation timestamps.\n",
      "    track_order\n",
      "        (T/F) Track attribute creation order if True. If omitted use\n",
      "        global default h5.get_config().track_order.\n",
      "    external\n",
      "        (Iterable of tuples) Sets the external storage property, thus\n",
      "        designating that the dataset will be stored in one or more\n",
      "        non-HDF5 files external to the HDF5 file.  Adds each tuple\n",
      "        of (name, offset, size) to the dataset's list of external files.\n",
      "        Each name must be a str, bytes, or os.PathLike; each offset and\n",
      "        size, an integer.  If only a name is given instead of an iterable\n",
      "        of tuples, it is equivalent to [(name, 0, h5py.h5f.UNLIMITED)].\n",
      "    allow_unknown_filter\n",
      "        (T/F) Do not check that the requested filter is available for use.\n",
      "        This should only be used with ``write_direct_chunk``, where the caller\n",
      "        compresses the data before handing it to h5py.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file.create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
